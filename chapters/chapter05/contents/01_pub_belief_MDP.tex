\label{sec:chap5-pub-belief-MDP}
As we aware, recursive learning in many steps can be complex and expensive even in cooperation problem. By using public agent formulation, we can reduce the problem into a single agent POMDP task, which would be easier to manage. This technique is proposed in \cite{nayyar2013decentralized} and extended to scale over by approximation and neural network in \cite{foerster2018bayesian}. 

The public belief MDP is based on the fact that every agent can somehow infer the underlying state given a public observation (can be an action too). After forming a belief on the state, each agent can execute an action, which conditions on its private observation and the belief over the state. Given a decoupled process, we can have a centralized agent that only infer the underlying state and distribute the common belief to each lower-level agent to execute its action with some instruction. The process can be summarized to fit our perspective as follows:
\begin{itemize}
    \item The public agent observes a public observation and construct a message $m_t \sim \pi^{\pri}_t(\cdot | o^{\pub}_t, a^{\pub}_t)$ with belief over state $\mathcal{B}_t = P(s_t | o^{\pub}_{\le t})$ where $o^{\pub}_{\le t}$ is the history of public policy till the time $t$
    \item The lower-level agent after receives the message from the higher-level agent will execute its action based on its private observation, the message given, and belief over state calculated using higher-level agent i.e $a^i_t \sim \pi^i(\cdot | m_t, \mathcal{B}_t, o^{\pri}_t)$. 
\end{itemize}
Please note that by having a centralized public belief agent makes the coordination problem much easier since each agent can reason about the other's action based on its the belief of other agent's private observation conditioned on message $m_t$. And, both of the agent and its higher-level counterpart will try to optimize the same reward. Note that we can train the public agent individually for each agent, however, we have to make sure that they are the same, which can be implemented by a public seed as a common-knowledge \cite{foerster2018bayesian}.