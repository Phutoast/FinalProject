\label{sec:chap6-future-work}
We have tackled 2 extensions to our MAPI framework, which are crucial fundamentally for multi-agent system: the ability to communicate and the ability to reason under uncertainty. There are still works untackled in this thesis including a more unify view of adversarial imitation learning and context aware agent in multi-agent setting. Furthermore, multi-tasking and distilling of multi-agent policy can also be an interesting problem. 

Looking back, investigating the effects of entropy regularization in opponent model and agent through the lens of exploration can be fruitful, as shown in \cite{mahajan2019maven} that some of the multi-agent algorithms do suffers from exploration problem. Would this also occur in entropy regularizated MARL algorithms ? is a question that requires further investigation.

In conclusion, there are 2 direction that ones can take. First, they can expand the family of MAPI algorithms by reinterpreting single agent algorithm and/or problems. Or, secondly, they can look in ward on analysing the performance that entropy regularization in multi-agent scenario. 