\label{sec:chap6-future-work}
We have tackled two extensions to our MAPI framework, which allows the agent to develop a fundamental ability for any multi-agent system, which are the ability to communicate and the ability to reason under uncertainty. There are still other extensions that are untackled in this thesis, including a unified view of adversarial imitation learning and context-aware agent in a multi-agent setting. Furthermore, multi-tasking and distilling of multi-agent policy can also be an interesting problem. 

Looking back, investigating the effects of entropy regularization in the opponent model and agent through the lens of exploration can be fruitful, as shown in \cite{mahajan2019maven} that some of the multi-agent algorithms do suffer from exploration problem. Would this also occur in entropy regularized MARL algorithms ? is a question that requires further investigation.

In conclusion, there are 2 major directions that ones can take. First, they can expand the family of MAPI algorithms by reinterpreting the single-agent algorithm and problems. Or, secondly, they can look inward on analyzing the performance that entropy regularization gives to a multi-agent algorithm. 