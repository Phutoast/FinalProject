We present a unified view of probabilistic multi-agent reinforcement learning, generalizing most of the probabilistic multi-agent reinforcement learning algorithms. With this framework, we can compare and contrast the advantages and disadvantages of each algorithm, which leads us to a decentralized training with decentralized execution algorithm that can be trained to find one of the Nash-Equilibrium strategies in general sum games. We believed that this is one of the first decentralized probabilistic reinforcement learning algorithms that can cope with general sum games. 